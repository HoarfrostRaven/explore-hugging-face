{"cells":[{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["import torch\n","from peft import LoraConfig, get_peft_model\n","from transformers import ChineseCLIPProcessor, ChineseCLIPModel"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading (…)lve/main/config.json: 100%|██████████| 3.01k/3.01k [00:00<?, ?B/s]\n","C:\\Users\\CZLZ9814\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Applications\\Projets\\model. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n","To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n","  warnings.warn(message)\n","Downloading pytorch_model.bin: 100%|██████████| 753M/753M [01:13<00:00, 10.2MB/s] \n","Downloading (…)rocessor_config.json: 100%|██████████| 342/342 [00:00<00:00, 343kB/s]\n","Downloading (…)solve/main/vocab.txt: 100%|██████████| 110k/110k [00:00<00:00, 8.75MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["trainable params: 794,880 || all params: 188,852,737 || trainable%: 0.420899380452188\n"]}],"source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","model = ChineseCLIPModel.from_pretrained(\"OFA-Sys/chinese-clip-vit-base-patch16\", cache_dir='../model').to(device)\n","processor = ChineseCLIPProcessor.from_pretrained(\"OFA-Sys/chinese-clip-vit-base-patch16\", cache_dir='../model')\n","\n","peft_config = LoraConfig(target_modules=[\"query\", \"value\"], inference_mode=False, r=16, lora_alpha=16, lora_dropout=0.1, bias=\"all\"\n",")\n","model = get_peft_model(model, peft_config)\n","model.to(device)\n","model.print_trainable_parameters()"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPNqGVQ3k5oyhRG3+di4GJH","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":0}
